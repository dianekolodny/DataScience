{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlIjEO+pPIII2KAAzylStH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dianekolodny/DataScience/blob/main/Pubmed_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Packages"
      ],
      "metadata": {
        "id": "8BwQbNzokzBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "!pip install adjustText\n",
        "!pip install mplcursors\n",
        "!pip install mpldatacursor"
      ],
      "metadata": {
        "id": "7zwpP6K-dpl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fetch journal articles from PubMed using search terms"
      ],
      "metadata": {
        "id": "inMJ5CJRky71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def fetch_article_details(article_id):\n",
        "    base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
        "    params = {\n",
        "        'db': 'pubmed',\n",
        "        'retmode': 'xml',\n",
        "        'id': article_id\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        print(f'Failed to retrieve article details for ID: {article_id}')\n",
        "        return None\n",
        "\n",
        "def parse_article_details(xml_data):\n",
        "    root = ET.fromstring(xml_data)\n",
        "    author_elements = root.findall('.//Author')\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "    for author_element in author_elements:\n",
        "        first_name_element = author_element.find('ForeName')\n",
        "        last_name_element = author_element.find('LastName')\n",
        "        affiliation_element = author_element.find('.//AffiliationInfo/Affiliation')\n",
        "\n",
        "        first_name = first_name_element.text if first_name_element is not None else ''\n",
        "        last_name = last_name_element.text if last_name_element is not None else ''\n",
        "        full_name = f'{first_name} {last_name}'\n",
        "\n",
        "        authors.append(full_name)\n",
        "\n",
        "        affiliation = affiliation_element.text if affiliation_element is not None else ''\n",
        "        affiliations.append(affiliation)\n",
        "\n",
        "    title_element = root.find('.//ArticleTitle')\n",
        "    abstract_element = root.find('.//Abstract/AbstractText')\n",
        "    pub_date_element = root.find('.//PubDate')\n",
        "    journal_element = root.find('.//Journal/Title')\n",
        "\n",
        "    title = title_element.text if title_element is not None else ''\n",
        "    abstract = abstract_element.text if abstract_element is not None else ''\n",
        "    pub_date = get_pub_date(pub_date_element) if pub_date_element is not None else ''\n",
        "    journal = journal_element.text if journal_element is not None else ''\n",
        "\n",
        "    return {\n",
        "        'authors': authors,\n",
        "        'affiliations': affiliations,\n",
        "        'title': title,\n",
        "        'abstract': abstract,\n",
        "        'pub_date': pub_date,\n",
        "        'journal': journal\n",
        "    }\n",
        "\n",
        "def get_pub_date(pub_date_element):\n",
        "    year_element = pub_date_element.find('.//Year')\n",
        "    month_element = pub_date_element.find('.//Month')\n",
        "    day_element = pub_date_element.find('.//Day')\n",
        "\n",
        "    year = year_element.text if year_element is not None else ''\n",
        "    month = month_element.text if month_element is not None else ''\n",
        "    day = day_element.text if day_element is not None else ''\n",
        "\n",
        "    return f'{year}-{month}-{day}'\n",
        "\n",
        "# Example usage\n",
        "search_term = 'immunoproteasome inhibitor'\n",
        "article_ids = search_pubmed(search_term)\n",
        "\n",
        "# Create lists to store data\n",
        "authors_list = []\n",
        "affiliations_list = []\n",
        "titles_list = []\n",
        "abstracts_list = []\n",
        "pub_dates_list = []\n",
        "journals_list = []\n",
        "links_list = []\n",
        "\n",
        "for article_id in article_ids:\n",
        "    article_data = fetch_article_details(article_id)\n",
        "    if article_data:\n",
        "        parsed_data = parse_article_details(article_data)\n",
        "        authors = parsed_data.get('authors', [])\n",
        "        affiliations = parsed_data.get('affiliations', [])\n",
        "        title = parsed_data.get('title', '')\n",
        "        abstract = parsed_data.get('abstract', '')\n",
        "        pub_date = parsed_data.get('pub_date', '')\n",
        "        journal = parsed_data.get('journal', '')\n",
        "\n",
        "        authors_str = ', '.join(authors)\n",
        "        affiliations_str = '\\n'.join(affiliations)\n",
        "\n",
        "        pubmed_link = f'https://pubmed.ncbi.nlm.nih.gov/{article_id}'\n",
        "\n",
        "        authors_list.append(authors_str)\n",
        "        affiliations_list.append(affiliations_str)\n",
        "        titles_list.append(title)\n",
        "        abstracts_list.append(abstract)\n",
        "        pub_dates_list.append(pub_date)\n",
        "        journals_list.append(journal)\n",
        "        links_list.append(pubmed_link)\n",
        "\n",
        "# Create a data frame\n",
        "df = pd.DataFrame({\n",
        "    'Authors': authors_list,\n",
        "    'Affiliations': affiliations_list,\n",
        "    'Title': titles_list,\n",
        "    'Abstract': abstracts_list,\n",
        "    'Publication Date': pub_dates_list,\n",
        "    'Journal': journals_list,\n",
        "    'Link': links_list\n",
        "})\n",
        "\n",
        "# Save the data frame as an Excel file\n",
        "output_file = 'pubmed_results.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Results saved to {output_file}\")"
      ],
      "metadata": {
        "id": "VPmt6aCEYev3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QXZnHmQQ0XGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "xr7Pwl7klIEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Authors and Affiliations by Count"
      ],
      "metadata": {
        "id": "Z1dYjsWuydN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def fetch_article_details(article_id):\n",
        "    base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
        "    params = {\n",
        "        'db': 'pubmed',\n",
        "        'retmode': 'xml',\n",
        "        'id': article_id\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        print(f'Failed to retrieve article details for ID: {article_id}')\n",
        "        return None\n",
        "\n",
        "def parse_article_details(xml_data):\n",
        "    root = ET.fromstring(xml_data)\n",
        "    author_elements = root.findall('.//Author')\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "    for author_element in author_elements:\n",
        "        first_name_element = author_element.find('ForeName')\n",
        "        last_name_element = author_element.find('LastName')\n",
        "        affiliation_element = author_element.find('.//AffiliationInfo/Affiliation')\n",
        "\n",
        "        first_name = first_name_element.text if first_name_element is not None else ''\n",
        "        last_name = last_name_element.text if last_name_element is not None else ''\n",
        "        full_name = f'{first_name} {last_name}'\n",
        "\n",
        "        authors.append(full_name)\n",
        "\n",
        "        affiliation = affiliation_element.text if affiliation_element is not None else ''\n",
        "        affiliations.append(affiliation)\n",
        "\n",
        "    return authors, affiliations\n",
        "\n",
        "# Example usage\n",
        "search_term = 'immunoproteasome inhibitor'\n",
        "article_ids = search_pubmed(search_term)\n",
        "\n",
        "affiliation_authors = {}\n",
        "\n",
        "for article_id in article_ids:\n",
        "    article_data = fetch_article_details(article_id)\n",
        "    if article_data:\n",
        "        authors, affiliations = parse_article_details(article_data)\n",
        "        for affiliation in affiliations:\n",
        "            if affiliation not in affiliation_authors:\n",
        "                affiliation_authors[affiliation] = set()\n",
        "            affiliation_authors[affiliation].update(authors)\n",
        "\n",
        "# Filter affiliations with author count greater than 1\n",
        "filtered_affiliations = [affiliation for affiliation, authors in affiliation_authors.items() if len(authors) > 1]\n",
        "filtered_counts = [len(affiliation_authors[affiliation]) for affiliation in filtered_affiliations]\n",
        "\n",
        "# Sort affiliations and counts in descending order of author count\n",
        "sorted_data = sorted(zip(filtered_affiliations, filtered_counts), key=lambda x: x[1], reverse=True)\n",
        "sorted_affiliations, sorted_counts = zip(*sorted_data)\n",
        "\n",
        "# Plot the bar chart\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(sorted_affiliations)), sorted_counts, align='center')\n",
        "plt.yticks(range(len(sorted_affiliations)), sorted_affiliations)\n",
        "plt.xlabel('Author Count')\n",
        "plt.ylabel('Affiliations')\n",
        "plt.title('Number of Authors by Affiliation (Author Count > 1)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "penlskpDdzpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe of Authors and Affiliations"
      ],
      "metadata": {
        "id": "0YF1Pmn7ym9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def fetch_article_details(article_id):\n",
        "    base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
        "    params = {\n",
        "        'db': 'pubmed',\n",
        "        'retmode': 'xml',\n",
        "        'id': article_id\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        print(f'Failed to retrieve article details for ID: {article_id}')\n",
        "        return None\n",
        "\n",
        "def parse_article_details(xml_data):\n",
        "    root = ET.fromstring(xml_data)\n",
        "    author_elements = root.findall('.//Author')\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "    for author_element in author_elements:\n",
        "        first_name_element = author_element.find('ForeName')\n",
        "        last_name_element = author_element.find('LastName')\n",
        "        affiliation_element = author_element.find('.//AffiliationInfo/Affiliation')\n",
        "\n",
        "        first_name = first_name_element.text if first_name_element is not None else ''\n",
        "        last_name = last_name_element.text if last_name_element is not None else ''\n",
        "        full_name = f'{first_name} {last_name}'\n",
        "\n",
        "        authors.append(full_name)\n",
        "\n",
        "        affiliation = affiliation_element.text if affiliation_element is not None else ''\n",
        "        affiliations.append(affiliation)\n",
        "\n",
        "    return authors, affiliations\n",
        "\n",
        "# Example usage\n",
        "search_term = 'immunoproteasome inhibitor'\n",
        "article_ids = search_pubmed(search_term)\n",
        "\n",
        "affiliations = []\n",
        "authors = []\n",
        "\n",
        "for article_id in article_ids:\n",
        "    article_data = fetch_article_details(article_id)\n",
        "    if article_data:\n",
        "        article_authors, article_affiliations = parse_article_details(article_data)\n",
        "        affiliations.extend(article_affiliations)\n",
        "        authors.extend(article_authors)\n",
        "\n",
        "# Create a data frame to store authors and affiliations\n",
        "df = pd.DataFrame({'Authors': authors, 'Affiliation': affiliations})\n",
        "\n",
        "# Display the data frame\n",
        "df\n"
      ],
      "metadata": {
        "id": "mc8iZhIxxXjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means Clustering of authors and affiliations"
      ],
      "metadata": {
        "id": "I0oMFVXZyuNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "def fetch_article_details(article_id):\n",
        "    base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
        "    params = {\n",
        "        'db': 'pubmed',\n",
        "        'retmode': 'xml',\n",
        "        'id': article_id\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        print(f'Failed to retrieve article details for ID: {article_id}')\n",
        "        return None\n",
        "\n",
        "def parse_article_details(xml_data):\n",
        "    root = ET.fromstring(xml_data)\n",
        "    author_elements = root.findall('.//Author')\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "    for author_element in author_elements:\n",
        "        first_name_element = author_element.find('ForeName')\n",
        "        last_name_element = author_element.find('LastName')\n",
        "        affiliation_element = author_element.find('.//AffiliationInfo/Affiliation')\n",
        "\n",
        "        first_name = first_name_element.text if first_name_element is not None else ''\n",
        "        last_name = last_name_element.text if last_name_element is not None else ''\n",
        "        full_name = f'{first_name} {last_name}'\n",
        "\n",
        "        authors.append(full_name)\n",
        "\n",
        "        affiliation = affiliation_element.text if affiliation_element is not None else ''\n",
        "        affiliations.append(affiliation)\n",
        "\n",
        "    return authors, affiliations\n",
        "\n",
        "# Example usage\n",
        "search_term = 'immunoproteasome inhibitor'\n",
        "article_ids = search_pubmed(search_term)\n",
        "\n",
        "affiliation_authors = {}\n",
        "\n",
        "for article_id in article_ids:\n",
        "    article_data = fetch_article_details(article_id)\n",
        "    if article_data:\n",
        "        authors, affiliations = parse_article_details(article_data)\n",
        "        for affiliation in affiliations:\n",
        "            if affiliation not in affiliation_authors:\n",
        "                affiliation_authors[affiliation] = []\n",
        "            affiliation_authors[affiliation].extend(authors)\n",
        "\n",
        "# Prepare data for clustering\n",
        "affiliations = list(affiliation_authors.keys())\n",
        "authors = list(affiliation_authors.values())\n",
        "\n",
        "# Vectorize the affiliations using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(affiliations)\n",
        "\n",
        "# Apply dimensionality reduction\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "normalizer = Normalizer(copy=False)\n",
        "lsa = make_pipeline(svd, normalizer)\n",
        "X_lsa = lsa.fit_transform(X)\n",
        "\n",
        "# Apply K-means clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(X_lsa)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Create a hover template with affiliation and author list\n",
        "hover_template = '<b>Affiliation:</b> %{text}<br><br><b>Authors:</b><br><div style=\"max-height:200px;overflow:auto;\">%{customdata}</div>'\n",
        "custom_data = ['<br>'.join(authors) for authors in authors]\n",
        "\n",
        "# Create a scatter plot using Plotly\n",
        "fig = go.Figure(data=go.Scatter(\n",
        "    x=X_lsa[:, 0],\n",
        "    y=X_lsa[:, 1],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        color=labels,\n",
        "        colorscale='viridis',\n",
        "        size=8,\n",
        "        line_width=1,\n",
        "    ),\n",
        "    hovertemplate=hover_template,\n",
        "    text=affiliations,\n",
        "    customdata=custom_data,\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Clustering Map of Authors by Affiliation',\n",
        "    xaxis_title='Component 1',\n",
        "    yaxis_title='Component 2',\n",
        "    coloraxis_colorbar=dict(\n",
        "        title='Cluster',\n",
        "    ),\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "oaQwFO5MhNcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe of Clusters - Authors and Affiliations"
      ],
      "metadata": {
        "id": "n5w_D0Hly-58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "\n",
        "# Create hover template with affiliation and author list\n",
        "hover_template = '<b>Affiliation:</b> %{text}<br><br><b>Authors:</b><br><div style=\"max-height:200px;overflow:auto;\">%{customdata}</div>'\n",
        "\n",
        "# Create a data frame to store authors and affiliations\n",
        "df = pd.DataFrame({'Affiliation': affiliations, 'Authors': authors})\n",
        "\n",
        "# Add clustering labels to the data frame\n",
        "df['Cluster'] = labels\n",
        "\n",
        "# Display the data frame\n",
        "df\n"
      ],
      "metadata": {
        "id": "FdDmwyaMooPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gn8GWK96u525"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}